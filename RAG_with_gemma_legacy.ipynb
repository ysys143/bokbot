{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install accelerate transformers sentence-transformers faiss-cpu -qq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!mkdir readmes\n",
    "!wget https://huggingface.co/datasets/pedrogengo/readmes/raw/main/transformer.md -O readmes/transformer.md\n",
    "!wget https://huggingface.co/datasets/pedrogengo/readmes/raw/main/pymatting.md -O readmes/pymatting.md\n",
    "!wget https://huggingface.co/datasets/pedrogengo/readmes/raw/main/yolo.md -O readmes/yolo.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import markdown\n",
    "import faiss\n",
    "import torch\n",
    "from bs4 import BeautifulSoup\n",
    "from huggingface_hub import login\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /Users/jaesolshin/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "key_path = '/Users/jaesolshin/key/HF_TOKEN.txt'\n",
    "os.environ[\"HF_TOKEN\"] = open(key_path, 'r', encoding='utf-8').read()\n",
    "login(os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def md_to_text(md):\n",
    "    html = markdown.markdown(md)\n",
    "    soup = BeautifulSoup(html, features='html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "def split_text(document_path, chunk_size, overlap):\n",
    "  with open(document_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "  content = md_to_text(content)\n",
    "  chunks = []\n",
    "  for i in range(0, len(content), chunk_size):\n",
    "    chunk = document_path + content[max(0, i-overlap):min(len(content), i+chunk_size)] #pymatting.md content[0:100]. -> pymatting.md content[100:200] ...\n",
    "    chunks.append(chunk)\n",
    "  return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "readmes_dir = \"readmes\"\n",
    "chunk_size = 700\n",
    "overlap = 100\n",
    "\n",
    "all_chunks = []\n",
    "for f in os.listdir(\"corrected_text\"):\n",
    "  if f[-2:] == \"md\":\n",
    "    all_chunks += split_text(os.path.join(readmes_dir, f), chunk_size, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(130, 384)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "_ = embedding_model.to(device)\n",
    "embeddings = embedding_model.encode(all_chunks)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing embeddings using FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = embeddings.shape[1] # 384\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Gemma 2B instruction tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697561246d434dad8ed8ebc7f26a1bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "\n",
    "model_id = \"google/gemma-2b-it\"\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"mps\",\n",
    "    torch_dtype=dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to generate the prompts (RAG and no RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_prompt(user_input):\n",
    "  chat = [\n",
    "      { \"role\": \"user\", \"content\": user_input },\n",
    "  ]\n",
    "  prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "  return prompt\n",
    "\n",
    "\n",
    "def create_rag_prompt(user_input, embedding_model, docs, db, k=5):\n",
    "\n",
    "  embedding = embedding_model.encode([user_input])\n",
    "  _, I = db.search(embedding, k)\n",
    "\n",
    "  context = \"Relevant documents:\\n\"\n",
    "  for i in I[0]:\n",
    "    context += f\"Doc {i+1}: {docs[i]}\\n\"\n",
    "\n",
    "  chat = [\n",
    "      { \"role\": \"user\", \"content\": f\"Use the documents to answer the user.\\n{context}\\n{user_input}\"},\n",
    "  ]\n",
    "  prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The authors of Pymatting are:\n",
      "\n",
      "* **David MacDiarmid**\n",
      "* **Mark P. Allen**\n",
      "* **David R. Reichman**\n",
      "* **Daniel R. Reichman**<eos>\n"
     ]
    }
   ],
   "source": [
    "query = \"who are the authors of pymatting?\"\n",
    "\n",
    "prompt = create_simple_prompt(query)\n",
    "inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=150)\n",
    "print(tokenizer.decode(outputs[0]).split(\"<start_of_turn>model\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "who are the authors of pymatting?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The authors of pymatting are:\n",
      "\n",
      "- Thomas Germer\n",
      "- Tobias Uelwer\n",
      "- Stefan Conrad\n",
      "- Stefan Harmeling<eos>\n"
     ]
    }
   ],
   "source": [
    "query = \"who are the authors of pymatting?\"\n",
    "\n",
    "prompt = create_rag_prompt(query, embedding_model, all_chunks, index, k=10)\n",
    "inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=150)\n",
    "print(tokenizer.decode(outputs[0]).split(\"<start_of_turn>model\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "Use the documents to answer the user.\n",
      "Relevant documents:\n",
      "Doc 127: readmes/pymatting.mdermer\n",
      "Tobias Uelwer\n",
      "Stefan Conrad\n",
      "Stefan Harmeling\n",
      "\n",
      "See also the list of contributors who participated in this project.\n",
      "Projects using PyMatting\n",
      "\n",
      "Rembg - an excellent tool for removing image backgrounds.\n",
      "PaddleSeg - a library for a wide range of image segmentation tasks.\n",
      "chaiNNer - a node-based image processing GUI.\n",
      "LSA-Matting - improving deep image matting via local smoothness assumption.\n",
      "\n",
      "License\n",
      "This project is licensed under the MIT License - see the LICENSE.md file for details\n",
      "Citing\n",
      "If you found PyMatting to be useful for your work, please consider citing our paper:\n",
      "@article{Germer2020,\n",
      "  doi = {10.21105/joss.02481},\n",
      "  url = {https://doi.org/10.21105/joss.02481},\n",
      "  year = {2020},\n",
      "  publisher = {The Open Journal},\n",
      "  volume = {5},\n",
      "  number = {54},\n",
      "  pages = {2481},\n",
      "  author = {Thomas \n",
      "Doc 125: readmes/pymatting.md=0.47.0\n",
      "* scipy>=1.1.0\n",
      "Additional requirements for GPU support\n",
      "* cupy-cuda90>=6.5.0 or similar\n",
      "* pyopencl>=2019.1.2\n",
      "Requirements to run the tests\n",
      "* pytest>=5.3.4\n",
      "Installation with PyPI\n",
      "bash\n",
      "pip3 install pymatting\n",
      "Installation from Source\n",
      "bash\n",
      "git clone https://github.com/pymatting/pymatting\n",
      "cd pymatting\n",
      "pip3 install .\n",
      "Example\n",
      "```python\n",
      "from pymatting import cutout\n",
      "cutout(\n",
      "    # input image path\n",
      "    \"data/lemur/lemur.png\",\n",
      "    # input trimap path\n",
      "    \"data/lemur/lemur_trimap.png\",\n",
      "    # output cutout path\n",
      "    \"lemur_cutout.png\")\n",
      "```\n",
      "More advanced examples\n",
      "Trimap Construction\n",
      "All implemented methods rely on trimaps which roughly classify the image into foreground, background and unknown regions.\n",
      "Trimaps are expected to be numpy.ndarrays of type np.float64  having the same shape as the input \n",
      "Doc 126: readmes/pymatting.mds.\n",
      "Trimaps are expected to be numpy.ndarrays of type np.float64  having the same shape as the input image with only one color-channel.\n",
      "Trimap values of 0.0 denote pixels which are 100% background.\n",
      "Similarly, trimap values of 1.0 denote pixels which are 100% foreground.\n",
      "All other values indicate unknown pixels which will be estimated by the algorithm.\n",
      "Testing\n",
      "Run the tests from the main directory:\n",
      "python3 tests/download_images.py\n",
      " pip3 install -r requirements_tests.txt\n",
      " pytest\n",
      "Currently 89% of the code is covered by tests.\n",
      "Upgrade\n",
      "bash\n",
      "pip3 install --upgrade pymatting\n",
      "python3 -c \"import pymatting\"\n",
      "Bug Reports, Questions and Pull-Requests\n",
      "Please, see our community guidelines.\n",
      "Authors\n",
      "\n",
      "Thomas Germer\n",
      "Tobias Uelwer\n",
      "Stefan Conrad\n",
      "Stefan Harmeling\n",
      "\n",
      "See also the list of contributors who participat\n",
      "Doc 109: readmes/yolo.mdssue-2168540003\n",
      "\n",
      "C# ONNX inference: https://github.com/WongKinYiu/yolov9/issues/95#issue-2155974619\n",
      "\n",
      "C# OpenVINO inference: https://github.com/WongKinYiu/yolov9/issues/95#issuecomment-1968131244\n",
      "\n",
      "OpenCV: https://github.com/WongKinYiu/yolov9/issues/113#issuecomment-1971327672\n",
      "\n",
      "Hugging Face demo: https://github.com/WongKinYiu/yolov9/issues/45#issuecomment-1961496943\n",
      "\n",
      "CoLab demo: https://github.com/WongKinYiu/yolov9/pull/18\n",
      "\n",
      "ONNXSlim export: https://github.com/WongKinYiu/yolov9/pull/37\n",
      "\n",
      "YOLOv9 ROS: https://github.com/WongKinYiu/yolov9/issues/144#issue-2164210644\n",
      "\n",
      "YOLOv9 ROS TensorRT: https://github.com/WongKinYiu/yolov9/issues/145#issue-2164218595\n",
      "\n",
      "YOLOv9 Julia: https://github.com/WongKinYiu/yolov9/issues/141#issuecomment-1973710107\n",
      "\n",
      "YOLOv9 MLX: https://github.com/WongKinYiu/yolov9/issues/258\n",
      "Doc 122: readmes/yolo.md \n",
      "\n",
      "* [https://github.com/AlexeyAB/darknet](https://github.com/AlexeyAB/darknet)\n",
      "* [https://github.com/WongKinYiu/yolor](https://github.com/WongKinYiu/yolor)\n",
      "* [https://github.com/WongKinYiu/yolov7](https://github.com/WongKinYiu/yolov7)\n",
      "* [https://github.com/VDIGPKU/DynamicDet](https://github.com/VDIGPKU/DynamicDet)\n",
      "* [https://github.com/DingXiaoH/RepVGG](https://github.com/DingXiaoH/RepVGG)\n",
      "* [https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5)\n",
      "* [https://github.com/meituan/YOLOv6](https://github.com/meituan/YOLOv6)\n",
      "\n",
      "\n",
      "Doc 123: readmes/pymatting.mdPyMatting: A Python Library for Alpha Matting\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "We introduce the PyMatting package for Python which implements various methods to solve the alpha matting problem.\n",
      "\n",
      "Website and Documentation: https://pymatting.github.io/\n",
      "Benchmarks: https://pymatting.github.io/benchmarks.html\n",
      "\n",
      "\n",
      "Given an input image and a hand-drawn trimap (top row), alpha matting estimates the alpha channel of a foreground object which can then be composed onto a different background (bottom row).\n",
      "PyMatting provides:\n",
      "- Alpha matting implementations for:\n",
      "  - Closed Form Alpha Matting [1]\n",
      "  - Large Kernel Matting [2]\n",
      "  - KNN Matting [3]\n",
      "  - Learning Based Digital Matting [4]\n",
      "  - Random Walk Matting [5]\n",
      "  - Shared Sampling Ma\n",
      "Doc 130: readmes/pymatting.mdng, S. (2020). Fast Multi-Level Foreground Estimation. arXiv preprint arXiv:2006.14970.\n",
      "Lemur image by Mathias Appel from https://www.flickr.com/photos/mathiasappel/25419442300/ licensed under CC0 1.0 Universal (CC0 1.0) Public Domain License.\n",
      "Doc 106: readmes/transformer.md = oct,\n",
      "    year = \"2020\",\n",
      "    address = \"Online\",\n",
      "    publisher = \"Association for Computational Linguistics\",\n",
      "    url = \"https://www.aclweb.org/anthology/2020.emnlp-demos.6\",\n",
      "    pages = \"38--45\"\n",
      "}\n",
      "Doc 128: readmes/pymatting.mdblisher = {The Open Journal},\n",
      "  volume = {5},\n",
      "  number = {54},\n",
      "  pages = {2481},\n",
      "  author = {Thomas Germer and Tobias Uelwer and Stefan Conrad and Stefan Harmeling},\n",
      "  title = {PyMatting: A Python Library for Alpha Matting},\n",
      "  journal = {Journal of Open Source Software}\n",
      "}\n",
      "References\n",
      "[1]\n",
      "Anat Levin, Dani Lischinski, and Yair Weiss. A closed-form solution to natural image matting. IEEE transactions on pattern analysis and machine intelligence, 30(2):228–242, 2007.\n",
      "[2]\n",
      "Kaiming He, Jian Sun, and Xiaoou Tang. Fast matting using large kernel matting laplacian matrices. In 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2165–2172. IEEE, 2010.\n",
      "[3]\n",
      "Qifeng Chen, Dingzeyu Li, and Chi-Keung Tang. Knn matting. IEEE transactions on pattern analysis and machine intellige\n",
      "Doc 21: readmes/transformer.mdPhilip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.\n",
      "BioGpt (from Microsoft Research AI4Science) released with the paper BioGPT: generative pre-trained transformer for biomedical text generation and mining by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu.\n",
      "BiT (from Google AI) released with the paper Big Transfer (BiT): General Visual Representation Learning by Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, Neil Houlsby.\n",
      "Blenderbot (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.\n",
      "BlenderbotSmall (from Faceb\n",
      "\n",
      "who are the authors of pymatting?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
